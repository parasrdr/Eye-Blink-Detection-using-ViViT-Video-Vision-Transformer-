{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","mount_file_id":"1Kekol12QFsPvAD9hR5Xa1GLOEwOkJ5cQ","authorship_tag":"ABX9TyNJu6MKjORFfZcH+k+xHwdv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ViViT Eye Blink Detection â€” Evaluation on Test Videos\n","\n","This notebook evaluates a fine-tuned ViViT model on raw `.mp4` eye videos\n","and reports Accuracy, Precision, Recall, and Confusion Matrix.\n","\n","No metadata or MediaPipe preprocessing is used during evaluation.\n"],"metadata":{"id":"wHW8tPFcUISe"}},{"cell_type":"markdown","source":["ðŸŸ¦ 2. Imports & Device Setup"],"metadata":{"id":"oR-xbRPhUguR"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    confusion_matrix,\n","    precision_recall_curve\n",")\n","\n","from transformers import VivitForVideoClassification\n"],"metadata":{"id":"-IHHq8hNbsTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","TEST_ROOT = \"/content/drive/MyDrive/eye_dataset_test\"  # blink / no_blink folders\n","MODEL_PATH = \"/content/drive/MyDrive/best_model(1).pth\"\n","\n","TARGET_FRAMES = 32\n","IMG_SIZE = 224\n"],"metadata":{"id":"rIoJvZLCby8P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŸ¦ 3. Load Trained ViViT Model"],"metadata":{"id":"uDGwNOEGVun8"}},{"cell_type":"code","source":["model = VivitForVideoClassification.from_pretrained(\n","    \"google/vivit-b-16x2-kinetics400\",\n","    num_labels=2,\n","    ignore_mismatched_sizes=True\n",")\n","\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n","model.to(device)\n","model.eval()\n"],"metadata":{"id":"FJDOhRFdcVyV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŸ¦ 3. Video Loading Utility"],"metadata":{"id":"ThAQWUnYUpPc"}},{"cell_type":"code","source":["def load_video_tensor(video_path, target_frames=32, size=224):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        frame = cv2.resize(frame, (size, size))\n","        frames.append(frame)\n","\n","    cap.release()\n","\n","    if len(frames) == 0:\n","        return None\n","\n","    frames = np.stack(frames)\n","\n","    # Temporal sampling\n","    idx = np.linspace(0, len(frames)-1, target_frames).astype(int)\n","    frames = frames[idx]\n","\n","    frames = torch.from_numpy(frames).float() / 255.0\n","    frames = frames.permute(0, 3, 1, 2)  # T C H W\n","    frames = frames.unsqueeze(0)         # 1 T C H W\n","\n","    return frames\n"],"metadata":{"id":"5hvlLHaEci1r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŸ¦ 4. Evaluation Dataset (MP4-based, FAST)"],"metadata":{"id":"sx1XB-gQVTsx"}},{"cell_type":"code","source":["all_probs = []\n","all_labels = []\n","\n","label_map = {\"no_blink\": 0, \"blink\": 1}\n","\n","video_list = []\n","for cls in [\"blink\", \"no_blink\"]:\n","    cls_dir = os.path.join(TEST_ROOT, cls)\n","    for f in os.listdir(cls_dir):\n","        if f.endswith(\".mp4\"):\n","            video_list.append((os.path.join(cls_dir, f), label_map[cls]))\n","\n","print(f\"Total test videos: {len(video_list)}\")\n"],"metadata":{"id":"DBZv4w_acr6j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŸ¦ 5. Run Evaluation"],"metadata":{"id":"EvvAdzo7WBTC"}},{"cell_type":"code","source":["with torch.no_grad():\n","    for video_path, label in tqdm(video_list, desc=\"Evaluating\"):\n","        video_tensor = load_video_tensor(video_path)\n","\n","        if video_tensor is None:\n","            continue\n","\n","        video_tensor = video_tensor.to(device)\n","        logits = model(video_tensor).logits\n","\n","        prob = torch.softmax(logits, dim=1)[0, 1].item()  # blink prob\n","\n","        all_probs.append(prob)\n","        all_labels.append(label)\n"],"metadata":{"id":"xUzvwyD4cySE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ðŸŸ¦ 6. Metrics"],"metadata":{"id":"59R9JWUhWPhG"}},{"cell_type":"code","source":["all_probs = np.array(all_probs)\n","all_labels = np.array(all_labels)\n","\n","precision, recall, thresholds = precision_recall_curve(\n","    all_labels, all_probs\n",")\n","\n","plt.figure(figsize=(6,5))\n","plt.plot(recall, precision)\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Precisionâ€“Recall Curve (ViViT Blink Detection)\")\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"vrfx0VbcdcIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n","best_idx = np.argmax(f1_scores)\n","\n","best_thresh = thresholds[best_idx]\n","print(f\"Best threshold (F1): {best_thresh:.3f}\")\n","print(f\"Precision: {precision[best_idx]:.3f}\")\n","print(f\"Recall   : {recall[best_idx]:.3f}\")\n"],"metadata":{"id":"4hsNIIoYfmHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["THRESH =0.05  # adjust visually from PR curve\n","\n","preds = (all_probs > THRESH).astype(int)\n","\n","acc = accuracy_score(all_labels, preds)\n","prec = precision_score(all_labels, preds)\n","rec = recall_score(all_labels, preds)\n","cm = confusion_matrix(all_labels, preds)\n","\n","print(f\"Accuracy : {acc:.4f}\")\n","print(f\"Precision: {prec:.4f}\")\n","print(f\"Recall   : {rec:.4f}\")\n","print(\"Confusion Matrix:\\n\", cm)\n"],"metadata":{"id":"Pw1mKTljdikG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrix(\n","    y_true,\n","    y_pred,\n","    class_names=(\"No Blink\", \"Blink\"),\n","    normalize=True,\n","    threshold=None,\n","    save_path=\"confusion_matrix.png\"\n","):\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm_norm = cm.astype(np.float32) / cm.sum(axis=1, keepdims=True)\n","    else:\n","        cm_norm = cm\n","\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","    im = ax.imshow(cm_norm, cmap=\"Blues\")\n","\n","    ax.set_xticks(np.arange(len(class_names)))\n","    ax.set_yticks(np.arange(len(class_names)))\n","    ax.set_xticklabels(class_names, fontsize=12)\n","    ax.set_yticklabels(class_names, fontsize=12)\n","\n","    ax.set_xlabel(\"Predicted Label\", fontsize=13)\n","    ax.set_ylabel(\"True Label\", fontsize=13)\n","\n","    title = \"Confusion Matrix â€“ ViViT Blink Detection\"\n","    if threshold is not None:\n","        title += f\" (Threshold = {threshold:.2f})\"\n","    if normalize:\n","        title += \"\\n(Row-Normalized)\"\n","\n","    ax.set_title(title, fontsize=14, pad=12)\n","\n","    # Annotate cells\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            if normalize:\n","                text = f\"{cm_norm[i, j]:.2f}\\n({cm[i, j]})\"\n","            else:\n","                text = str(cm[i, j])\n","\n","            ax.text(\n","                j, i, text,\n","                ha=\"center\", va=\"center\",\n","                fontsize=12,\n","                color=\"white\" if cm_norm[i, j] > 0.5 else \"black\"\n","            )\n","\n","    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n","    cbar.ax.tick_params(labelsize=11)\n","\n","    plt.tight_layout()\n","    plt.savefig(save_path, dpi=200)\n","    plt.show()\n","\n","    print(f\"Saved confusion matrix to {save_path}\")\n"],"metadata":{"id":"-WBLei9Lnyae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for t in [0.5, 0.2, 0.1, 0.05, 0.02]:\n","    preds = (all_probs > t).astype(int)\n","    rec = recall_score(all_labels, preds, zero_division=0)\n","    prec = precision_score(all_labels, preds, zero_division=0)\n","    print(f\"thr={t:.2f} | precision={prec:.3f} | recall={rec:.3f}\")\n"],"metadata":{"id":"RRv6u-lcoQoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_confusion_matrix(\n","    all_labels,\n","    preds,\n","    threshold=THRESH,\n","    save_path=\"confusion_matrix_thresh_0.2.png\"\n",")\n"],"metadata":{"id":"n84N2Sxen4Oq"},"execution_count":null,"outputs":[]}]}